# main.py

import pandas as pd
import numpy as np
import math # ìˆ˜í•™ í•¨ìˆ˜ ì‚¬ìš©ì„ ìœ„í•´ math ëª¨ë“ˆ ì¶”ê°€
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from filtering.contents_based import ContentBasedRecommender
from filtering.collaborative import CollaborativeRecommender
from filtering.blender_mlp import MLPBlender

# Pandas ì¶œë ¥ ì˜µì…˜ ì„¤ì •
pd.set_option('display.max_columns', None)
pd.set_option('display.width', 1000)

# --- ğŸ¯ ìœ„ì¹˜ ì •ë³´ ë° ìƒìˆ˜ ì •ì˜ ---
COORDINATES = {
    'í›„ë¬¸': (37.29633029410662, 126.97061603024721),
    'ë¶ë¬¸': (37.296274335479666, 126.9764159771293),
    'ì •ë¬¸': (37.29100570424096, 126.97417156623229),
    'ì„±ê· ê´€ëŒ€ì—­': (37.29986776148395, 126.97219805873624)
}
R = 6371 # ì§€êµ¬ ë°˜ì§€ë¦„ (km)

# --- ìƒìˆ˜ ì„¤ì • ---
TEST_USER_ID = 2020312857 
INPUT_FEATURE_DIM = 5      
EPOCHS = 30                
TOP_N = 10                 

# --- í•¨ìˆ˜ ì •ì˜ ---

def haversine(lat1, lon1, lat2, lon2):
    """
    í•˜ë²„ì‚¬ì¸ ê³µì‹ì„ ì‚¬ìš©í•˜ì—¬ ë‘ ì¢Œí‘œ ê°„ì˜ ê±°ë¦¬ë¥¼ km ë‹¨ìœ„ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    lat1_rad, lon1_rad = math.radians(lat1), math.radians(lon1)
    lat2_rad, lon2_rad = math.radians(lat2), math.radians(lon2)

    dlon = lon2_rad - lon1_rad
    dlat = lat2_rad - lat1_rad

    a = math.sin(dlat / 2)**2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon / 2)**2
    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))
    
    return R * c

def calculate_distance_score(user_location_name, menu_location_name):
    """
    ìœ„ì¹˜ ì´ë¦„ì„ ë°›ì•„ í•˜ë²„ì‚¬ì¸ ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ê³ , ì´ë¥¼ ì ìˆ˜(0~1)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    (Score = exp(-distance / L0) )
    """
    if user_location_name not in COORDINATES or menu_location_name not in COORDINATES:
        return 0.1 # ìœ„ì¹˜ ì •ë³´ê°€ ì—†ì„ ê²½ìš° ë‚®ì€ ì ìˆ˜ ë¶€ì—¬

    lat1, lon1 = COORDINATES[user_location_name]
    lat2, lon2 = COORDINATES[menu_location_name]
    
    distance_km = haversine(lat1, lon1, lat2, lon2)

    # L0: íŠ¹ì„± ê±°ë¦¬ (0.5kmë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê±°ë¦¬ê°€ ë©€ì–´ì§ˆìˆ˜ë¡ ì ìˆ˜ê°€ ê¸‰ê²©íˆ í•˜ë½í•˜ë„ë¡ ì„¤ì •)
    L0 = 0.5 
    
    # ì ìˆ˜: ê±°ë¦¬ê°€ 0ì´ë©´ 1, ê±°ë¦¬ê°€ ë©€ì–´ì§ˆìˆ˜ë¡ 0ì— ìˆ˜ë ´
    score = math.exp(-distance_km / L0)
    
    return score

def generate_hybrid_features(ratings_df, menu_df, cb_recommender, cf_recommender):
    """
    MLP í•™ìŠµì— ì‚¬ìš©í•  X (ì…ë ¥ íŠ¹ì§•)ì™€ Y (ì •ë‹µ í‰ì ) ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    print("\n[3] í•˜ì´ë¸Œë¦¬ë“œ íŠ¹ì§• í–‰ë ¬ (X, Y) ìƒì„± ì‹œì‘...")
    
    data = ratings_df.copy()
    
    # NOTE: ëª¨ë“  ìœ ì €ì˜ í˜„ì¬ ìœ„ì¹˜ê°€ 'ì •ë¬¸'ì´ë¼ê³  ê°€ì •í•˜ê³  ê³„ì‚°í•©ë‹ˆë‹¤.
    CURRENT_USER_LOCATION = 'ì •ë¬¸' 
    DUMMY_PROFILE = "í•œì‹ ì°Œê°œ ì–¼í°í•œ ë°¥ì´ë‘" 
    
    # 1. ë©”ë‰´ ë°ì´í„° ì¡°ì¸
    data = pd.merge(data, menu_df[['id', 'price', 'location', 'avg_rating']], 
                    left_on='menu_id', right_on='id', how='left')
    
    # 2. CB Score (ì½˜í…ì¸  ìœ ì‚¬ë„) ê³„ì‚°
    data['CB_Score'] = data.apply(
        lambda row: cb_recommender.get_single_cb_score(row['menu_id'], DUMMY_PROFILE),
        axis=1
    )

    # 3. CF Score (ì˜ˆìƒ í‰ì ) ê³„ì‚°
    data['CF_Score'] = data.apply(
        lambda row: cf_recommender.model.predict(
            uid=row['user_id'], iid=row['menu_id']
        ).est,
        axis=1
    )
    
    # 4. Distance Score ê³„ì‚° (ì¢Œí‘œ ê¸°ë°˜)
    data['Distance_Score'] = data['location'].apply(
        lambda menu_loc: calculate_distance_score(CURRENT_USER_LOCATION, menu_loc)
    )
    
    # 5. X í–‰ë ¬ ë° Y ë²¡í„° ì¶”ì¶œ (avg_ratingì€ menu_dfì—ì„œ ë³‘í•©ë˜ì–´ ìˆë‹¤ê³  ê°€ì •)
    X = data[['CB_Score', 'CF_Score', 'price', 'Distance_Score', 'avg_rating']].values
    Y = data['rating'].values 
    
    print(f"íŠ¹ì§• í–‰ë ¬ X ìƒì„± ì™„ë£Œ. Shape: {X.shape}")
    return X, Y


def main():
    
    # --- 1. ë°ì´í„° ë° ì¶”ì²œê¸° ì´ˆê¸°í™” ---
    ratings_df = pd.read_csv('./data/ratings_data.csv')
    
    # menu_data.csvì— 'avg_rating' ì»¬ëŸ¼ì´ ì—†ë‹¤ê³  ê°€ì •í•˜ê³  ê³„ì‚°í•˜ì—¬ ì¶”ê°€
    menu_df = pd.read_csv('./data/menu_data.csv')
    menu_ratings = ratings_df.groupby('menu_id')['rating'].mean().reset_index()
    menu_ratings.columns = ['id', 'avg_rating']
    
    # avg_ratingì„ menu_dfì— ë³‘í•©
    menu_df = pd.merge(menu_df, menu_ratings, on='id', how='left').fillna(0) 
    
    # CB Recommender ì´ˆê¸°í™”
    cb_recommender = ContentBasedRecommender()
    
    # CF Recommender ì´ˆê¸°í™” (ëª¨ë¸ í•™ìŠµ í¬í•¨)
    cf_recommender = CollaborativeRecommender()
    
    
    # --- 2. MLP í•™ìŠµ ë°ì´í„°ì…‹ ì¤€ë¹„ ---
    X, Y = generate_hybrid_features(ratings_df, menu_df, cb_recommender, cf_recommender)
    
    # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ì…‹ ë¶„ë¦¬
    X_train, X_test, Y_train, Y_test = train_test_split(
        X, Y, test_size=0.2, random_state=42
    )

    
    # --- 3. MLP ëª¨ë¸ í•™ìŠµ ë° ê²€ì¦ ---
    
    mlp_blender = MLPBlender(input_dim=X.shape[1])
    
    print("\n[4] MLP ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    # í•™ìŠµ ê²°ê³¼ë¥¼ history ê°ì²´ë¡œ ë°›ì•„ ê³¼ì í•© ê´€ì¸¡ ìë£Œë¡œ ì‚¬ìš© ê°€ëŠ¥
    history = mlp_blender.train(X_train, Y_train, epochs=EPOCHS, batch_size=4) 
    
    # í…ŒìŠ¤íŠ¸ ì…‹ ê²€ì¦
    Y_pred_test = mlp_blender.predict(X_test)
    test_rmse = np.sqrt(mean_squared_error(Y_test, Y_pred_test))
    
    print("-" * 50)
    print(f"âœ… ìµœì¢… í…ŒìŠ¤íŠ¸ ì…‹ RMSE: {test_rmse:.4f}")
    print("-" * 50)
    
    
    # --- 4. ìµœì¢… ì¶”ì²œ ë¡œì§ (ì˜ˆì‹œ) ---
    # (ì‹¤ì œ ì¶”ì²œì€ unrated ë©”ë‰´ ê¸°ë°˜ìœ¼ë¡œ X_predictë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.)
    
    recommendation_results = pd.DataFrame({
        'Predicted_Rating': final_pred_scores,
        'Actual_Rating': Y_test 
    })
    
    # ì˜ˆìƒ í‰ì ì´ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬ (ì˜ˆì‹œ)
    print(f"\n[5] ìµœì¢… MLP ì˜ˆì¸¡ ê²°ê³¼ ìƒ˜í”Œ (Top {TOP_N})")
    print(recommendation_results.sort_values(by='Predicted_Rating', ascending=False).head(TOP_N))
    

if __name__ == "__main__":
    # ContentBasedRecommender í´ë˜ìŠ¤ì— get_single_cb_score ë©”ì„œë“œë¥¼ ì„ì‹œë¡œ ì—°ê²°í•©ë‹ˆë‹¤.
    # (ì›ë˜ filtering/contents_based.pyì— ì§ì ‘ êµ¬í˜„ë˜ì–´ì•¼ í•¨)
    from sklearn.metrics.pairwise import cosine_similarity
    
    def get_single_cb_score(self, menu_id, user_profile):
        menu_index = self.menu_df[self.menu_df['id'] == menu_id].index
        if len(menu_index) == 0: return 0.0
        
        user_vector = self.tfidf_vectorizer.transform([user_profile])
        menu_vector = self.menu_feature_matrix[menu_index[0]]
        
        return cosine_similarity(user_vector, menu_vector)[0][0]
        
    from filtering.contents_based import ContentBasedRecommender # ì¬ì„í¬íŠ¸
    ContentBasedRecommender.get_single_cb_score = get_single_cb_score
    
    # MLP ì˜ˆì¸¡ ìƒ˜í”Œ ì¶œë ¥ì„ ìœ„í•œ ì„ì‹œ ë³€ìˆ˜ í• ë‹¹
    # ì´ ë¶€ë¶„ì€ ì‹¤ì œ ì˜ˆì¸¡ ì‹œë‚˜ë¦¬ì˜¤ê°€ ì•„ë‹ˆë¯€ë¡œ, ê²½ê³ ë¥¼ í”¼í•˜ê¸° ìœ„í•´ ì„ì‹œë¡œ ì •ì˜í•©ë‹ˆë‹¤.
    final_pred_scores = np.array([5, 4, 3, 2, 1, 4.5, 3.5, 2.5, 1.5, 5.0, 4.0, 3.0])
    Y_test = np.array([5, 4, 3, 2, 1, 4, 3, 2, 1, 5, 4, 3]) 

    main()