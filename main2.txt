import pandas as pd
import numpy as np
import math
import os
import argparse 
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from filtering.contents_based import ContentBasedRecommender
from filtering.collaborative import CollaborativeRecommender
from filtering.blender_mlp import MLPBlender
from tensorflow.keras.models import load_model
from sklearn.metrics.pairwise import cosine_similarity # main 로직이 아닌 __init__ 밖에 있어야 함

# --- 위치 정보 및 상수 정의 ---
COORDINATES = {
    's': (37.29986776148395, 126.97219805873624), 
    'b': (37.29633029410662, 126.97061603024721), 
    'n': (37.296274335479666, 126.9764159771293), 
    'f': (37.29100570424096, 126.97417156623229), 
}
R = 6371 
MODEL_PATH = 'model/final_mlp_model.keras'
INPUT_FEATURE_DIM = 5 # MLP 입력 차원 상수를 함수 외부에 명시
GLOBAL_X_TEST = None
GLOBAL_Y_TEST = None

# --- 데이터 파일 경로 ---
DATA_PATHS = {
    'menu': './data/menu_data.csv',
    'rest': './data/rest_data.csv',
    'user': './data/user_data.csv',
    'rating': './data/rating_data.csv',
}

# --- 지리 및 유틸리티 함수 ---

def haversine(lat1, lon1, lat2, lon2):
    """하버사인 공식을 사용하여 두 좌표 간의 거리를 km 단위로 계산합니다."""
    lat1_rad, lon1_rad = math.radians(lat1), math.radians(lon1)
    lat2_rad, lon2_rad = math.radians(lat2), math.radians(lon2)

    dlon = lon2_rad - lon1_rad
    dlat = lat2_rad - lat1_rad

    a = math.sin(dlat / 2)**2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon / 2)**2
    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))
    return R * c

def calculate_distance_score(user_loc_char, rest_lat, rest_lon):
    """현재 사용자 위치와 식당 좌표 간의 거리 점수를 계산합니다."""
    if user_loc_char not in COORDINATES: return 0.0

    user_lat, user_lon = COORDINATES[user_loc_char]
    distance_km = haversine(user_lat, user_lon, rest_lat, rest_lon)

    L0 = 0.5 
    score = math.exp(-distance_km / L0)
    return score

def get_cb_preference(user_id, query_str):
    """
    CB Score 계산에 사용할 최종 선호도 문자열을 결정합니다.
    (쿼리 우선순위 로직)
    """
    user_df = pd.read_csv(DATA_PATHS['user'])
    user_pref = user_df[user_df['user_id'] == user_id]['preference'].iloc[0]
    
    if pd.isna(query_str) or query_str == "":
        return user_pref
    
    return user_pref + " " + query_str


# --- 데이터 로드 및 특징 생성 (MLP 학습용) ---

def generate_hybrid_features(ratings_df, menu_df, rest_df, user_df, cb_recommender, cf_recommender):
    """
    MLP 학습에 사용할 X (입력 특징)와 Y (정답 평점) 데이터를 생성합니다.
    (MLP 학습 데이터는 rating_data를 기반으로 하며, 예측이 아닌 정답 평점 Y를 타겟으로 함)
    """
    print("\n[3] 하이브리드 특징 행렬 (X, Y) 생성 시작...")
    
    # 1. 데이터 로드 (함수 내에서 read_csv 호출 제거 - 인수로 받음)
    
    # 2. 데이터 병합 (rating_df -> menu_df -> rest_df)
    data = ratings_df.copy()
    # rating_x (rating_data.rating)과 rating_y (rest_data.rating)를 구분하기 위해 suffixes 사용
    data = pd.merge(data, menu_df[['menu_id', 'rest_id', 'price', 'features']], on='menu_id', how='left')
    data = pd.merge(data, rest_df[['rest_id', 'Latitude', 'Longitude', 'rating']], on='rest_id', how='left', suffixes=('_menu', '_rest')) 
    
    # 3. 특징 계산
    data['CB_Score'] = data.apply(
        lambda row: cb_recommender.get_single_cb_score(row['menu_id'], row['user_id'], user_df),
        axis=1
    )
    
    data['CF_Score'] = data.apply(
        lambda row: cf_recommender.model.predict(
            uid=row['user_id'], iid=row['menu_id']
        ).est,
        axis=1
    )
    
    # Distance Score: 평가 당시 위치를 사용
    location_map = {v: k for k, v in [('성균관대역', 's'), ('정문', 'f'), ('후문', 'b'), ('북문', 'n')]} 
    data['Distance_Score'] = data.apply(
        lambda row: calculate_distance_score(
            location_map.get(row['location'], 'f'), # 평가 당시 위치 (문자열->코드)
            row['Latitude'], row['Longitude']
        ),
        axis=1
    )
    
    # 4. X, Y 추출
    # Price와 Avg. Rating 정규화를 위한 Scaler는 MLPBlender에서 처리됨을 가정하고, raw data를 넘김
    # 'rating_rest'는 rest_data의 rating, 'rating_menu'는 rating_data의 rating (정답)
    X = data[['CB_Score', 'CF_Score', 'price', 'Distance_Score', 'rating_rest']].values 
    Y = data['rating_menu'].values 
    
    print(f"특징 행렬 X 생성 완료. Shape: {X.shape}")
    return X, Y

# --- 메인 실행 함수 ---

def main():
    
    parser = argparse.ArgumentParser(description="SKKU Menu Hybrid Recommendation Engine")
    parser.add_argument('--i', type=int, required=True, help='User ID (e.g., 2020)')
    parser.add_argument('--l', type=str, required=True, choices=COORDINATES.keys(), help='Current Location Code (s, b, n, f)')
    parser.add_argument('--b', type=int, default=10, help='Budget (in thousand KRW, e.g., 10 for 10,000 KRW)')
    parser.add_argument('--q', type=str, default="", help='Optional query for content filtering (e.g., "치즈가 들어간 메뉴")')
    args = parser.parse_args()
    
    USER_ID = args.i
    USER_LOC_CHAR = args.l
    USER_BUDGET = args.b * 1000
    USER_QUERY = args.q

    # X_test, Y_test는 None으로 초기화 (학습 분기에서만 채워짐)
    X_test, Y_test = None, None
    X_train_full, Y_train_full = None, None
    
    print("-" * 60)
    print(f"사용자 요청: ID={USER_ID}, 위치={USER_LOC_CHAR}, 예산={USER_BUDGET}원, 쿼리='{USER_QUERY}'")
    print("-" * 60)

    # 1. 모든 데이터 로드
    try:
        ratings_df = pd.read_csv(DATA_PATHS['rating'])
        menu_df = pd.read_csv(DATA_PATHS['menu'])
        rest_df = pd.read_csv(DATA_PATHS['rest'])
        user_df = pd.read_csv(DATA_PATHS['user'])
    except FileNotFoundError as e:
        print(f"Error: 필수 데이터 파일 로드 실패: {e}")
        return

    # 2. 추천기 인스턴스 초기화 (CF 모델 학습 포함)
    cb_recommender = ContentBasedRecommender(data_path=DATA_PATHS['menu'])
    cf_recommender = CollaborativeRecommender(ratings_path=DATA_PATHS['rating'], menu_path=DATA_PATHS['menu'])
    
    
    # 3. MLP 학습 및 로드 로직
    
    # A. 저장된 모델 로드 시도
    if os.path.exists(MODEL_PATH):
        print(f"\n[4] 저장된 MLP 모델 로드 중: {MODEL_PATH}")
        
        # Custom Metric 정의 (로드 시 필수)
        def root_mean_squared_error(y_true, y_pred):
             return np.sqrt(mean_squared_error(y_true, y_pred))
             
        # load_model을 사용하여 모델을 로드
        mlp_model_loaded = load_model(MODEL_PATH, custom_objects={'root_mean_squared_error': root_mean_squared_error})
        
        # MLPBlender 객체 생성 후 로드된 모델로 대체
        mlp_blender = MLPBlender(input_dim=INPUT_FEATURE_DIM)
        mlp_blender.model = mlp_model_loaded 
        
        # 모델 로드 시에도 X_train_full을 생성하여 예측 및 스케일러에 대비
        X_train_full, Y_train_full = generate_hybrid_features(ratings_df, menu_df, rest_df, user_df, cb_recommender, cf_recommender)

    # B. 모델이 없을 경우 학습 진행 및 저장
    else:
        print(f"\n[4] 저장된 모델 없음. MLP 학습 시작...")
        
        # 특징 행렬 X, Y 생성 (학습 데이터)
        X_train_full, Y_train_full = generate_hybrid_features(ratings_df, menu_df, rest_df, user_df, cb_recommender, cf_recommender)
        
        # 학습/검증 셋 분리
        X_train, X_test_local, Y_train, Y_test_local = train_test_split(
            X_train_full, Y_train_full, test_size=0.2, random_state=42
        )
        # X_test, Y_test에 분리된 테스트 셋 할당
        X_test, Y_test = X_test_local, Y_test_local

        mlp_blender = MLPBlender(input_dim=X_train_full.shape[1])
        
        # 모델 학습
        mlp_blender.train(X_train, Y_train, epochs=30, batch_size=4) 
        
        # 학습 완료 후 모델 저장
        os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)
        mlp_blender.model.save(MODEL_PATH)
        print(f"✅ MLP 모델 학습 완료 및 저장됨: {MODEL_PATH}")
    
    
    # 4. 최종 추천 후보군 생성 (Hard Filtering)
    
    # 4-1. 알레르기 및 예산 필터링 (Hard Filtering)
    user_allergy = user_df[user_df['user_id'] == USER_ID]['allergy'].iloc[0]
    
    candidate_df = menu_df[(menu_df['price'] <= USER_BUDGET) & (~menu_df['features'].str.contains(user_allergy, na=False))].copy()
    
    # 5. 최종 예측 특징 생성 및 예측 (실제 추천 로직)
    # TODO: X_predict 행렬 생성 및 예측 로직 추가 필요

    # 6. (샘플 예측) 테스트 셋에 대해 예측 및 출력
    if X_test is not None:
        X_predict_test = X_test
        Y_test_display = Y_test
    else:
        # 모델 로드 시, X_train_full에서 임시 샘플을 사용
        X_predict_test = X_train_full[0:10]
        Y_test_display = Y_train_full[0:10]

    Y_pred_test = mlp_blender.predict(X_predict_test)
    test_rmse = np.sqrt(mean_squared_error(Y_test_display, Y_pred_test))
    
    print("-" * 60)
    print(f"✅ 최종 MLP 테스트 셋 RMSE: {test_rmse:.4f}")
    
    # 7. 최종 추천 결과 출력 (예시)
    recommendation_results = pd.DataFrame({
        'Predicted_Rating': Y_pred_test.flatten(),
        'Actual_Rating': Y_test_display
    })
    
    print(f"\n[6] 최종 MLP 예측 결과 샘플 (Top 10)")
    print(recommendation_results.sort_values(by='Predicted_Rating', ascending=False).head(10))


if __name__ == "__main__":
    # ContentBasedRecommender 클래스에 get_single_cb_score 메서드를 임시로 연결합니다.
    from sklearn.metrics.pairwise import cosine_similarity
    
    def get_single_cb_score(self, menu_id, user_id, user_df):
        user_pref = user_df[user_df['user_id'] == user_id]['preference'].iloc[0]
        
        menu_index = self.menu_df[self.menu_df['menu_id'] == menu_id].index
        if len(menu_index) == 0: return 0.0
        
        user_vector = self.tfidf_vectorizer.transform([user_pref])
        menu_vector = self.menu_feature_matrix[menu_index[0]]
        
        return cosine_similarity(user_vector, menu_vector)[0][0]
        
    from filtering.contents_based import ContentBasedRecommender
    ContentBasedRecommender.get_single_cb_score = get_single_cb_score
    
    main()