import pandas as pd
import numpy as np
import os
import tensorflow as tf

# [ìš”ì²­í•˜ì‹  ì„í¬íŠ¸ ê²½ë¡œ ì ìš©]
from filtering.contents_based import ContentBasedRecommender
from filtering.collaborative import CollaborativeRecommender
from filtering.blender_mlp import MLPBlender
from filtering.graph_model import GraphRecommender
from utils import (
    DATA_PATHS, calculate_distance_score, IS_BASELINE,
    MLP_MODEL_PATH, SCALER_PATH, GRAPH_MODEL_PATH, INPUT_FEATURE_DIM
)

# [ì§„ë‹¨ìš© í”Œë˜ê·¸] True: GNN ì ìˆ˜ë¡œë§Œ ë­í‚¹ ì‚°ì • (ì§„ë‹¨ìš©), False: MLP ì‚¬ìš© (ê¸°ë³¸)
TEST_PURE_GNN = False 

def load_models():
    """ëª¨ë¸ë“¤ì„ ë©”ëª¨ë¦¬ì— í•œ ë²ˆë§Œ ë¡œë“œí•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    print("ëª¨ë¸ ë° ë°ì´í„° ë¡œë”© ì¤‘...")
    
    # ë°ì´í„° ë¡œë“œ
    menu_df = pd.read_csv(DATA_PATHS['menu'])
    rest_df = pd.read_csv(DATA_PATHS['rest'])
    ratings_df = pd.read_csv(DATA_PATHS['rating'])
    user_df = pd.read_csv(DATA_PATHS['user'])
    
    # ì¶”ì²œê¸° ì´ˆê¸°í™”
    cb_recommender = ContentBasedRecommender(DATA_PATHS['menu'])
    cf_recommender = CollaborativeRecommender(DATA_PATHS['rating'], DATA_PATHS['menu'])
    
    gnn_recommender = None

    if not IS_BASELINE:
        gnn_recommender = GraphRecommender(DATA_PATHS['rating'], DATA_PATHS['menu'])
        if os.path.exists(GRAPH_MODEL_PATH):
            gnn_recommender.load_model(GRAPH_MODEL_PATH)
            print("âœ… GNN ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")
        else:
            print("âš ï¸ [Warning] GNN ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    # MLP ë¡œë“œ
    mlp_blender = MLPBlender(input_dim=INPUT_FEATURE_DIM)
    if os.path.exists(MLP_MODEL_PATH):
        mlp_blender.model = tf.keras.models.load_model(MLP_MODEL_PATH)
        mlp_blender.load_scaler(SCALER_PATH)
        print("âœ… MLP ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")
    else:
        print(f"âŒ Error: MLP ëª¨ë¸ íŒŒì¼({MLP_MODEL_PATH})ì´ ì—†ìŠµë‹ˆë‹¤.")
        # [ìˆ˜ì •] ë°˜í™˜ ê°’ ê°œìˆ˜ ë§ì¶¤ (8ê°œ)
        return None, None, None, None, None, None, None, None

    return menu_df, rest_df, ratings_df, user_df, cb_recommender, cf_recommender, gnn_recommender, mlp_blender

def evaluate_single_user(user_id, true_menu_ids, models_data, top_k=10, verbose=False):
    """ë‹¨ì¼ ì‚¬ìš©ìì— ëŒ€í•œ Recall@Kë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    (menu_df, rest_df, ratings_df, user_df, cb, cf, gnn, mlp) = models_data
    
    # 1. ì‚¬ìš©ì ì„ í˜¸ë„(Preference) ê°€ì ¸ì˜¤ê¸°
    user_row = user_df[user_df['user_id'].astype(str) == str(user_id)]
    if user_row.empty:
        if verbose: print(f"User {user_id} ì •ë³´ ì—†ìŒ - Skip")
        return 0.0
    user_pref = user_row['preference'].iloc[0]

    # 2. ì „ì²´ ë©”ë‰´ í›„ë³´êµ° ìƒì„±
    candidate_df = menu_df.copy()
    
    # 3. Feature ìƒì„±
    # A. CB Score
    candidate_df['CB_Score'] = candidate_df['menu_id'].apply(
        lambda x: cb.get_single_cb_score(x, user_pref)
    )
    
    # B. CF Score
    cf_scores = cf.get_predicted_scores(user_id, candidate_df['menu_id'].tolist())
    cf_score_map = {mid: score for mid, score in cf_scores}
    candidate_df['CF_Score'] = candidate_df['menu_id'].map(cf_score_map)
    
    # C. Graph Score (KeyError ë°©ì§€ë¥¼ ìœ„í•´ 0.0ìœ¼ë¡œ ë¯¸ë¦¬ ì´ˆê¸°í™”)
    candidate_df['Graph_Score'] = 0.0
    if not IS_BASELINE and gnn:
        candidate_df['Graph_Score'] = candidate_df['menu_id'].apply(
            lambda x: gnn.get_graph_score(user_id, x)
        )

        g_min = candidate_df['Graph_Score'].min()
        g_max = candidate_df['Graph_Score'].max()
        if g_max > g_min:
             candidate_df['Graph_Score'] = (candidate_df['Graph_Score'] - g_min) / (g_max - g_min)
    
    # D. Meta Scores
    candidate_df = pd.merge(candidate_df, rest_df[['rest_id', 'Latitude', 'Longitude', 'rating']], on='rest_id', how='left')
    candidate_df.rename(columns={'rating': 'Avg_Rating'}, inplace=True)
    candidate_df['Avg_Rating'] = candidate_df['Avg_Rating'].fillna(3.0)

    # ê±°ë¦¬ ì ìˆ˜: í›„ë¬¸('b') ê¸°ì¤€ìœ¼ë¡œ ê³ ì •
    TARGET_LOCATION = 'b' 
    candidate_df['Distance_Score'] = candidate_df.apply(
        lambda row: calculate_distance_score(TARGET_LOCATION, row['Latitude'], row['Longitude']), 
        axis=1
    )
    
    # 4. ì˜ˆì¸¡ (ì§„ë‹¨ ëª¨ë“œ vs ì¼ë°˜ ëª¨ë“œ)
    if TEST_PURE_GNN and not IS_BASELINE:
        # [ì§„ë‹¨ìš©] GNN ì ìˆ˜ë§Œìœ¼ë¡œ ë­í‚¹ ì‚°ì • (MLP ë¬´ì‹œ)
        candidate_df['Predicted_Rating'] = candidate_df['Graph_Score']
    else:
        # [ì¼ë°˜ìš©] MLP ì‚¬ìš©
        if IS_BASELINE:
            X_eval = candidate_df[['CB_Score', 'CF_Score', 'price', 'Distance_Score', 'Avg_Rating']].values
        else:
            X_eval = candidate_df[['CB_Score', 'CF_Score', 'Graph_Score', 'price', 'Distance_Score', 'Avg_Rating']].values
        
        candidate_df['Predicted_Rating'] = mlp.predict(X_eval)
    
    # 5. ê²°ê³¼ í™•ì¸
    top_n_df = candidate_df.sort_values(by='Predicted_Rating', ascending=False).head(top_k)
    recommended_ids = top_n_df['menu_id'].tolist()
    
    # 6. Recall ê³„ì‚°
    hits = set(true_menu_ids) & set(recommended_ids)
    recall = len(hits) / len(true_menu_ids) if len(true_menu_ids) > 0 else 0.0
    
    if verbose:
        print(f"User {user_id}: ì •ë‹µ {len(true_menu_ids)}ê°œ ì¤‘ {len(hits)}ê°œ ì ì¤‘ -> Recall: {recall*100:.1f}%")
        
    return recall

def main():
    print(f"\n--- ì „ì²´ ì„±ëŠ¥ í‰ê°€ ì‹œì‘ (MODE: {'BASELINE' if IS_BASELINE else 'GNN'}) ---")
    if TEST_PURE_GNN and not IS_BASELINE:
        print("ğŸ“¢ [ì§„ë‹¨ ëª¨ë“œ] GNN ì ìˆ˜ ë‹¨ë… í‰ê°€ ì¤‘ì…ë‹ˆë‹¤.")

    # 1. ëª¨ë¸ ë¡œë“œ
    models_data = load_models()
    if models_data[-1] is None: return
    
    ratings_df = models_data[2]

    # 2. ì •ë‹µì§€(Ground Truth) ìƒì„± (í‰ì  4.0 ì´ìƒë§Œ ì •ë‹µìœ¼ë¡œ ê°„ì£¼)
    good_ratings = ratings_df[ratings_df['rating'] >= 4.0]
    user_ground_truth = good_ratings.groupby('user_id')['menu_id'].apply(list).to_dict()
    
    print(f"\nì´ {len(user_ground_truth)}ëª…ì˜ ì‚¬ìš©ìì— ëŒ€í•´ í‰ê°€ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\n")

    # 3. ì „ì²´ ì‚¬ìš©ì í‰ê°€
    total_recall = 0
    count = 0
    top_k = 10
    
    for user_id, true_ids in user_ground_truth.items():
        recall = evaluate_single_user(user_id, true_ids, models_data, top_k=top_k, verbose=True)
        total_recall += recall
        count += 1
        
    # 4. ìµœì¢… ê²°ê³¼ ì¶œë ¥
    avg_recall = total_recall / count if count > 0 else 0
    print("-" * 50)
    print(f"ğŸ“Š ìµœì¢… í‰ê°€ ê²°ê³¼ (Top-{top_k})")
    print(f"   - ì´ í‰ê°€ ìœ ì € ìˆ˜: {count}ëª…")
    print(f"   - Average Recall : {avg_recall * 100:.2f}%")
    print("-" * 50)

if __name__ == "__main__":
    main()